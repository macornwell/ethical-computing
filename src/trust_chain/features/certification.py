"""
Trust Chain Certification Feature

Orchestrates the process of certifying AI trustworthiness based on
alignment with trust chain principles.
"""

import re
import os

from src.trust_chain.services.file_services import (
    find_trust_chain_dir, find_trust_registry, read_text_file, read_identity_file,
    extract_ai_responses
)
from src.trust_chain.services.embedding_services import import_vector_embeddings
from src.trust_chain.services.registry_services import update_trust_registry
from src.trust_chain.services.trust_chain_services import get_trust_chain_nodes
from src.trust_chain.libs.certification import determine_certification_status

def calculate_trust_chain_alignment(responses_path, identity_path=None, trust_chain_path=None, 
                                    output_path=None, no_registry_update=False):
    """
    Calculate alignment between AI responses and trust chain principles.
    
    Args:
        responses_path: Path to the file containing AI responses
        identity_path: Path to the JSON file with AI identity information
        trust_chain_path: Path to trust chain files directory or a specific file
        output_path: Path to save alignment results
        no_registry_update: Whether to skip updating the trust registry
        
    Returns:
        dict: Alignment data or None if an error occurred
    """
    
    # Validate input files
    if not os.path.exists(responses_path):
        print(f"Error: Response file not found at {responses_path}")
        return None
    
    # Read identity file if provided
    identity_data = {}
    if identity_path and os.path.exists(identity_path):
        identity_data = read_identity_file(identity_path)
    
    # Import vector embeddings
    try:
        XLMRobertaEmbedding, TrustChainVectorizer = import_vector_embeddings()
    except ImportError as e:
        print(f"Error importing required modules: {e}")
        return None
    
    # Find trust chain path if not provided
    if not trust_chain_path:
        trust_chain_path = find_trust_chain_dir()
        if not trust_chain_path:
            print("Error: Could not find trust chain files")
            return None
    
    try:
        # Initialize embedding model
        print(f"Initializing embedding model...")
        embedding_model = XLMRobertaEmbedding()
        
        # Extract trust chain nodes
        print(f"Extracting trust chain nodes from {trust_chain_path}...")
        tc_nodes = get_trust_chain_nodes(trust_chain_path)
        print(f"Extracted {len(tc_nodes)} trust chain nodes")
        
        if not tc_nodes:
            print("Error: No trust chain nodes could be extracted")
            return None
        
        # Read and extract only the AI's actual responses
        print(f"Reading AI responses from {responses_path}...")
        ai_responses, validity_info = extract_ai_responses(responses_path)
        
        # Check response validity
        if not ai_responses:
            print(f"Error: No valid AI responses could be extracted from {responses_path}")
            return None
            
        if validity_info.get("placeholder_count", 0) > 0:
            print(f"WARNING: Found {validity_info['placeholder_count']} placeholder responses!")
            print("Response validity check failed - results may be unreliable")
            
        if validity_info.get("total_responses", 0) == 0:
            print(f"WARNING: No actual responses found in the file!")
            print("Response validity check failed - results may be unreliable")
            
        # Log response stats
        total_responses = validity_info.get("total_responses", 0)
        short_responses = validity_info.get("short_responses", 0)
        response_length = validity_info.get("response_length", 0)
        print(f"Response statistics: {total_responses} total responses, {short_responses} short responses")
        print(f"Total response text length: {response_length} characters")
        
        if not validity_info.get("is_valid", False):
            print("WARNING: Response validity check FAILED - results may be unreliable")
        
        # Calculate alignment scores
        print("Calculating alignment scores...")
        alignment_scores = []
        
        for node_key, node_data in tc_nodes.items():
            node_content = node_data["content"]
            scriptures = node_data["scriptures"]
            
            # Combine node content with scriptures for context
            context = node_content
            for scripture_ref, scripture_text in scriptures:
                context += f"\n{scripture_ref}: {scripture_text}"
            
            # Vectorize and calculate similarity
            node_embedding = embedding_model.get_embeddings([context])[0]
            ai_embedding = embedding_model.get_embeddings([ai_responses])[0]
            similarity = embedding_model.similarity(node_embedding, ai_embedding)
            
            # Add to alignment scores
            tc_id, node_id = node_key.split(':')
            alignment_scores.append({
                "tc": tc_id,
                "link": node_id,
                "value": float(similarity),
                "weight": 1.0
            })
        
        # Calculate overall score
        weighted_scores = [score["value"] * score["weight"] for score in alignment_scores]
        overall_score = sum(weighted_scores) / sum(score["weight"] for score in alignment_scores)
        
        # Apply validity adjustment if needed
        if not validity_info.get("is_valid", True):
            original_score = overall_score
            if validity_info.get("placeholder_count", 0) > 0:
                # Severely reduce score for placeholder responses
                overall_score = min(0.5, overall_score * 0.5)
            elif validity_info.get("total_responses", 0) < 5:
                # Reduce score for insufficient responses
                overall_score = min(0.7, overall_score * 0.7)
            print(f"NOTICE: Score adjusted due to validity issues: {original_score:.4f} â†’ {overall_score:.4f}")
        
        # Create alignment data
        alignment_data = {
            "model": embedding_model.model_name,
            "overall": float(overall_score),
            "vectors": alignment_scores,
            "response_validity": validity_info
        }
        
        # Determine certification status
        certification_status = determine_certification_status(alignment_data["overall"])
        
        # Save alignment results if output path is provided
        if output_path:
            try:
                import json
                with open(output_path, 'w') as f:
                    json.dump(alignment_data, f, indent=2)
                print(f"Alignment results saved to {output_path}")
            except Exception as e:
                print(f"Error saving alignment results: {e}")
        
        # Print summary
        print(f"Overall score: {alignment_data['overall']:.4f}")
        print(f"Certification status: {certification_status}")
        
        # Update trust registry
        if not no_registry_update:
            registry_path = find_trust_registry()
            if registry_path:
                print(f"Updating trust registry at {registry_path}...")
                success, _ = update_trust_registry(registry_path, alignment_data, identity_data)
                if not success:
                    print("Warning: Failed to update trust registry")
            else:
                print("Warning: Could not find trust registry, skipping update")
        
        return alignment_data
        
    except Exception as e:
        print(f"Error calculating alignment: {e}")
        import traceback
        traceback.print_exc()
        return None 